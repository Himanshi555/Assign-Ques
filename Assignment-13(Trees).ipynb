{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.1- Import the libraries and dataset. Print the head and shape of dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>1.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B  1  1.1  1.2  1.3\n",
       "0  R  1    1    1    2\n",
       "1  R  1    1    1    3\n",
       "2  R  1    1    1    4\n",
       "3  R  1    1    1    5\n",
       "4  R  1    1    2    1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data ')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(624, 5)\n"
     ]
    }
   ],
   "source": [
    " print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['B', '1', '1.1', '1.2', '1.3'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 624 entries, 0 to 623\n",
      "Data columns (total 5 columns):\n",
      "B      624 non-null object\n",
      "1      624 non-null int64\n",
      "1.1    624 non-null int64\n",
      "1.2    624 non-null int64\n",
      "1.3    624 non-null int64\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 24.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=624, step=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.2- Slice the dataset. Save the first column as y(Target) and rest of the columns as X(Features). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.values[:, 1:5]\n",
    "Y = data.values[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.3- Split the dataset by using train_test_split(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "X_train, X_test, Y_train, Y_test= tts(X , Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.4- Use DecisionTree with criterion \n",
    "\n",
    "a. Gini\n",
    "\n",
    "b. Entropy\n",
    "\n",
    "Print the accuracy score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\")\n",
    "clf_gini.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = clf_gini.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Actual Predicted\n",
      "0        R         B\n",
      "1        L         L\n",
      "2        B         L\n",
      "3        R         R\n",
      "4        L         L\n",
      "5        L         L\n",
      "6        R         R\n",
      "7        B         L\n",
      "8        L         L\n",
      "9        R         R\n",
      "10       R         R\n",
      "11       R         R\n",
      "12       R         B\n",
      "13       R         R\n",
      "14       L         L\n",
      "15       L         L\n",
      "16       R         R\n",
      "17       R         R\n",
      "18       R         R\n",
      "19       L         L\n",
      "20       R         R\n",
      "21       R         R\n",
      "22       L         L\n",
      "23       L         L\n",
      "24       R         B\n",
      "25       R         R\n",
      "26       R         R\n",
      "27       L         L\n",
      "28       L         L\n",
      "29       R         R\n",
      "..     ...       ...\n",
      "158      R         R\n",
      "159      L         L\n",
      "160      L         L\n",
      "161      R         R\n",
      "162      R         R\n",
      "163      L         L\n",
      "164      L         L\n",
      "165      L         L\n",
      "166      R         R\n",
      "167      L         L\n",
      "168      R         R\n",
      "169      R         R\n",
      "170      L         L\n",
      "171      R         R\n",
      "172      L         B\n",
      "173      R         B\n",
      "174      B         L\n",
      "175      L         L\n",
      "176      R         R\n",
      "177      L         L\n",
      "178      R         R\n",
      "179      L         B\n",
      "180      R         R\n",
      "181      R         B\n",
      "182      L         L\n",
      "183      R         R\n",
      "184      R         L\n",
      "185      R         R\n",
      "186      R         R\n",
      "187      R         R\n",
      "\n",
      "[188 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame({'Actual': Y_test, 'Predicted':Y_pred})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  8  3]\n",
      " [12 75  0]\n",
      " [11  3 75]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.04      0.08      0.06        12\n",
      "          L       0.87      0.86      0.87        87\n",
      "          R       0.96      0.84      0.90        89\n",
      "\n",
      "avg / total       0.86      0.80      0.83       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm, classification_report as cr\n",
    "print(cm(Y_test, Y_pred))\n",
    "print(cr(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  80.31914893617021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Print Accuracy Score\n",
    "print( 'Accuracy is ', accuracy_score(Y_test,Y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "clf_entropy.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_en = clf_entropy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Actual Predicted\n",
      "0        R         B\n",
      "1        L         L\n",
      "2        B         L\n",
      "3        R         R\n",
      "4        L         L\n",
      "5        L         L\n",
      "6        R         R\n",
      "7        B         L\n",
      "8        L         L\n",
      "9        R         R\n",
      "10       R         R\n",
      "11       R         R\n",
      "12       R         L\n",
      "13       R         R\n",
      "14       L         L\n",
      "15       L         L\n",
      "16       R         R\n",
      "17       R         R\n",
      "18       R         R\n",
      "19       L         L\n",
      "20       R         R\n",
      "21       R         R\n",
      "22       L         L\n",
      "23       L         L\n",
      "24       R         B\n",
      "25       R         R\n",
      "26       R         R\n",
      "27       L         L\n",
      "28       L         L\n",
      "29       R         R\n",
      "..     ...       ...\n",
      "158      R         R\n",
      "159      L         L\n",
      "160      L         L\n",
      "161      R         R\n",
      "162      R         R\n",
      "163      L         L\n",
      "164      L         L\n",
      "165      L         L\n",
      "166      R         R\n",
      "167      L         L\n",
      "168      R         R\n",
      "169      R         R\n",
      "170      L         L\n",
      "171      R         R\n",
      "172      L         B\n",
      "173      R         B\n",
      "174      B         B\n",
      "175      L         L\n",
      "176      R         R\n",
      "177      L         L\n",
      "178      R         R\n",
      "179      L         B\n",
      "180      R         R\n",
      "181      R         B\n",
      "182      L         L\n",
      "183      R         R\n",
      "184      R         L\n",
      "185      R         R\n",
      "186      R         R\n",
      "187      R         R\n",
      "\n",
      "[188 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame({'Actual': Y_test, 'Predicted':Y_pred_en})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  7  3]\n",
      " [14 72  1]\n",
      " [10  4 75]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.08      0.17      0.11        12\n",
      "          L       0.87      0.83      0.85        87\n",
      "          R       0.95      0.84      0.89        89\n",
      "\n",
      "avg / total       0.86      0.79      0.82       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cm(Y_test, Y_pred_en))\n",
    "print(cr(Y_test, Y_pred_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  79.25531914893617\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy Score\n",
    "print( \"Accuracy is \", accuracy_score(Y_test,Y_pred_en)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.5- Use RandomForset with criterion \n",
    "\n",
    "a. Gini\n",
    "b. Entropy\n",
    "\n",
    "Print the accuracy score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_gini = RandomForestClassifier(criterion = \"gini\")\n",
    "model_gini.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_rfc = model_gini.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Actual Predicted\n",
      "0        R         L\n",
      "1        L         L\n",
      "2        B         L\n",
      "3        R         R\n",
      "4        L         L\n",
      "5        L         L\n",
      "6        R         R\n",
      "7        B         R\n",
      "8        L         L\n",
      "9        R         R\n",
      "10       R         R\n",
      "11       R         R\n",
      "12       R         L\n",
      "13       R         R\n",
      "14       L         L\n",
      "15       L         B\n",
      "16       R         R\n",
      "17       R         R\n",
      "18       R         R\n",
      "19       L         L\n",
      "20       R         R\n",
      "21       R         R\n",
      "22       L         L\n",
      "23       L         L\n",
      "24       R         R\n",
      "25       R         R\n",
      "26       R         R\n",
      "27       L         L\n",
      "28       L         L\n",
      "29       R         R\n",
      "..     ...       ...\n",
      "158      R         R\n",
      "159      L         L\n",
      "160      L         L\n",
      "161      R         R\n",
      "162      R         R\n",
      "163      L         L\n",
      "164      L         L\n",
      "165      L         L\n",
      "166      R         R\n",
      "167      L         L\n",
      "168      R         R\n",
      "169      R         R\n",
      "170      L         L\n",
      "171      R         R\n",
      "172      L         B\n",
      "173      R         R\n",
      "174      B         L\n",
      "175      L         L\n",
      "176      R         R\n",
      "177      L         L\n",
      "178      R         R\n",
      "179      L         L\n",
      "180      R         R\n",
      "181      R         L\n",
      "182      L         L\n",
      "183      R         R\n",
      "184      R         L\n",
      "185      R         R\n",
      "186      R         R\n",
      "187      R         R\n",
      "\n",
      "[188 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame({'Actual': Y_test, 'Predicted':Y_pred_rfc})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  7  5]\n",
      " [ 7 79  1]\n",
      " [ 3  7 79]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.00      0.00      0.00        12\n",
      "          L       0.85      0.91      0.88        87\n",
      "          R       0.93      0.89      0.91        89\n",
      "\n",
      "avg / total       0.83      0.84      0.84       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cm(Y_test, Y_pred_rfc))\n",
    "print(cr(Y_test, Y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  84.04255319148936\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy Score\n",
    "print (\"Accuracy is \", accuracy_score(Y_test,Y_pred_rfc)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_entropy = RandomForestClassifier(criterion='entropy')\n",
    "model_entropy.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_rfc_en = model_entropy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Actual Predicted\n",
      "0        R         R\n",
      "1        L         L\n",
      "2        B         R\n",
      "3        R         R\n",
      "4        L         L\n",
      "5        L         L\n",
      "6        R         R\n",
      "7        B         R\n",
      "8        L         L\n",
      "9        R         R\n",
      "10       R         R\n",
      "11       R         R\n",
      "12       R         L\n",
      "13       R         R\n",
      "14       L         L\n",
      "15       L         B\n",
      "16       R         R\n",
      "17       R         R\n",
      "18       R         R\n",
      "19       L         L\n",
      "20       R         R\n",
      "21       R         R\n",
      "22       L         L\n",
      "23       L         L\n",
      "24       R         R\n",
      "25       R         R\n",
      "26       R         R\n",
      "27       L         L\n",
      "28       L         L\n",
      "29       R         R\n",
      "..     ...       ...\n",
      "158      R         R\n",
      "159      L         L\n",
      "160      L         L\n",
      "161      R         B\n",
      "162      R         R\n",
      "163      L         L\n",
      "164      L         L\n",
      "165      L         L\n",
      "166      R         R\n",
      "167      L         L\n",
      "168      R         R\n",
      "169      R         R\n",
      "170      L         L\n",
      "171      R         R\n",
      "172      L         B\n",
      "173      R         B\n",
      "174      B         L\n",
      "175      L         L\n",
      "176      R         R\n",
      "177      L         L\n",
      "178      R         R\n",
      "179      L         B\n",
      "180      R         R\n",
      "181      R         R\n",
      "182      L         L\n",
      "183      R         R\n",
      "184      R         L\n",
      "185      R         R\n",
      "186      R         R\n",
      "187      R         R\n",
      "\n",
      "[188 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame({'Actual': Y_test, 'Predicted':Y_pred_rfc_en})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  5  6]\n",
      " [11 76  0]\n",
      " [ 7  2 80]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.05      0.08      0.06        12\n",
      "          L       0.92      0.87      0.89        87\n",
      "          R       0.93      0.90      0.91        89\n",
      "\n",
      "avg / total       0.87      0.84      0.85       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cm(Y_test, Y_pred_rfc_en))\n",
    "print(cr(Y_test, Y_pred_rfc_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  83.51063829787235\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy Score\n",
    "print (\"Accuracy is \", accuracy_score(Y_test,Y_pred_rfc_en)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
